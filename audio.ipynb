{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-17T23:15:21.289248Z",
     "end_time": "2023-04-17T23:15:24.662718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgeffert/SUR/venv/lib/python3.9/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import ikrlib as ilib\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import scipy\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "cepstral_mean_subtraction_enabled = False\n",
    "delta_coefficients_enabled = True\n",
    "coefficients_normalization = True\n",
    "data_pre_emphasis = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T23:15:24.664037Z",
     "end_time": "2023-04-17T23:15:24.666109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing silence from records in directory target_train\n",
      "Removing silence from records in directory non_target_train\n"
     ]
    }
   ],
   "source": [
    "def audio_adjust(dir):\n",
    "    min_silence_len = 1000  # Minimálna dĺžka ticha (ms)\n",
    "    silence_thresh = -44    # prah ticha (dB)\n",
    "\n",
    "    print(f\"Removing silence from records in directory {dir}\")\n",
    "    if not os.path.isdir(dir + \"/rs\"):\n",
    "        os.mkdir(dir + \"/rs\")\n",
    "    for f in os.listdir(dir):\n",
    "        if f[-3:] == \"wav\":\n",
    "            input_file = dir + \"/\" + f\n",
    "            audio = AudioSegment.from_wav(input_file)\n",
    "            nonsilent_intervals = detect_nonsilent(audio, min_silence_len, silence_thresh)\n",
    "\n",
    "            # Zkonkatenuj invervaly kde nie je ticho\n",
    "            non_silent_audio = AudioSegment.empty()\n",
    "            for start, end in nonsilent_intervals:\n",
    "                non_silent_audio += audio[start:end]\n",
    "\n",
    "            # Ulož audio\n",
    "            output_file = dir + \"/rs/\" + f\n",
    "            non_silent_audio.export(output_file, format=\"wav\")\n",
    "\n",
    "audio_adjust(\"target_train\")\n",
    "audio_adjust(\"non_target_train\")\n",
    "audio_adjust(\"target_dev\")\n",
    "audio_adjust(\"non_target_dev\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T23:06:23.915636Z",
     "end_time": "2023-04-17T23:07:42.779418Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reduce_noise(dir):\n",
    "    print(f\"Removing noise from records in directory {dir}\")\n",
    "    if not os.path.isdir(dir + \"/rn\"):\n",
    "        os.mkdir(dir + \"/rn\")\n",
    "    for f in os.listdir(dir):\n",
    "        if f[-3:] == \"wav\":\n",
    "            input_file = dir + \"/rs/\" + f\n",
    "\n",
    "            # Load the audio file\n",
    "            audio, sr = librosa.load(input_file, sr=None)\n",
    "\n",
    "            # Select a portion of the audio that contains only noise (e.g., the first 0.5 seconds)\n",
    "            noise_sample = audio[:int(sr * 0.5)]\n",
    "\n",
    "            # Perform noise reduction using the noise sample\n",
    "            reduced_audio = nr.reduce_noise(y=audio, sr=sr, y_noise=noise_sample)\n",
    "\n",
    "            # Save the noise-reduced audio to a new file\n",
    "            output_file = dir + \"/rn/\" + f\n",
    "            sf.write(output_file, reduced_audio, sr)\n",
    "\n",
    "reduce_noise(\"target_train\")\n",
    "reduce_noise(\"non_target_train\")\n",
    "reduce_noise(\"target_dev\")\n",
    "reduce_noise(\"non_target_dev\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T23:07:42.782130Z",
     "end_time": "2023-04-17T23:07:58.118640Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_augumentation(dir):\n",
    "    print(f\"Removing noise from records in directory {dir}\")\n",
    "    for f in os.listdir(dir):\n",
    "        if f[-3:] == \"wav\":\n",
    "            input_file = dir + \"/\" + f\n",
    "            print(\"Data augumentation of file: \" + input_file)\n",
    "\n",
    "            time_stretched_audio = ilib.apply_time_stretching(input_file)\n",
    "            pitch_shifted_audio = ilib.apply_pitch_shifting(input_file, semitones=2)\n",
    "            time_shifted_audio = ilib.apply_time_shifting(input_file, shift_ms=500)\n",
    "\n",
    "            # find the index of the \".\" in the filename\n",
    "            dot_index = input_file.index(\".\")\n",
    "\n",
    "            # insert \"aug\" between \"audio\" and \".wav\"\n",
    "            stretched_file = input_file[:dot_index-5] + \"_stretched_aug\" + input_file[dot_index-5:dot_index] + input_file[dot_index:]\n",
    "            pitch_shifted_file = input_file[:dot_index-5] + \"_pitch_shifted_aug\" + input_file[dot_index-5:dot_index] + input_file[dot_index:]\n",
    "            time_shifted_file = input_file[:dot_index-5] + \"_time_shifted_aug\" + input_file[dot_index-5:dot_index] + input_file[dot_index:]\n",
    "\n",
    "            time_stretched_audio.export(stretched_file, format=\"wav\")\n",
    "            pitch_shifted_audio.export(pitch_shifted_file, format=\"wav\")\n",
    "            time_shifted_audio.export(time_shifted_file, format=\"wav\")\n",
    "\n",
    "data_augumentation(\"target_train/rn\")\n",
    "data_augumentation(\"non_target_train/rn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T22:44:41.471050Z",
     "end_time": "2023-04-17T22:45:56.161313Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_emphasis(dir):\n",
    "    data = []\n",
    "    for f in os.listdir(dir):\n",
    "        if f[-3:] == \"wav\":\n",
    "            input_file = dir + \"/\" + f\n",
    "            print(\"Proccessing input file: \" + input_file)\n",
    "            sample_rate, audio_samples = ilib.read_wav_file(input_file)\n",
    "\n",
    "            emphasized_audio = ilib.apply_pre_emphasis(audio_samples)\n",
    "\n",
    "            assert(sample_rate==16000)\n",
    "            data.append(ilib.extract_mfcc(emphasized_audio, sample_rate))\n",
    "    return data\n",
    "\n",
    "if data_pre_emphasis:\n",
    "    train_t = np.vstack(pre_emphasis('target_train/rn'))\n",
    "    train_n = np.vstack(pre_emphasis('non_target_train/rn'))\n",
    "\n",
    "    test_t = pre_emphasis('target_dev/rn')\n",
    "    test_n = pre_emphasis('non_target_dev/rn')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T22:44:00.616501Z",
     "end_time": "2023-04-17T22:44:22.755681Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not data_pre_emphasis:\n",
    "    train_t = ilib.wav16khz2mfcc('target_train/rn').values()\n",
    "    train_n = ilib.wav16khz2mfcc('non_target_train/rn').values()\n",
    "\n",
    "    test_t = ilib.wav16khz2mfcc('target_dev/rn').values()\n",
    "    test_n = ilib.wav16khz2mfcc('non_target_dev/rn').values()\n",
    "\n",
    "    # Koeficienty sa konkatenuju do jedneho poľa\n",
    "    train_t = np.vstack(list(train_t))\n",
    "    train_n = np.vstack(list(train_n))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:13:10.262252Z",
     "end_time": "2023-04-17T21:13:10.296787Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "    normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
    "    return normalized_data\n",
    "\n",
    "if coefficients_normalization:\n",
    "    train_t = min_max_normalize(train_t)\n",
    "    train_n = min_max_normalize(train_n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:13:10.298746Z",
     "end_time": "2023-04-17T21:13:10.354975Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_deltas(cepstral_coeffs, window_size=2):\n",
    "    num_frames, num_coeffs = cepstral_coeffs.shape\n",
    "    deltas = np.zeros((num_frames, num_coeffs))\n",
    "\n",
    "    for t in range(num_frames):\n",
    "        window_start = max(0, t - window_size)\n",
    "        window_end = min(num_frames, t + window_size + 1)\n",
    "        window_indices = np.arange(window_start, window_end)\n",
    "        window_weights = window_indices - t\n",
    "\n",
    "        weighted_sum = np.sum(window_weights[:, np.newaxis] * cepstral_coeffs[window_indices, :], axis=0)\n",
    "        weight_sum_squared = np.sum(window_weights ** 2)\n",
    "\n",
    "        deltas[t] = weighted_sum / weight_sum_squared\n",
    "\n",
    "    return deltas\n",
    "\n",
    "if delta_coefficients_enabled:\n",
    "    train_t_delta_coeffs = compute_deltas(train_t, window_size=2)\n",
    "    train_n_delta_coeffs = compute_deltas(train_n, window_size=2)\n",
    "\n",
    "    train_t_derivative_delta_coeffs = compute_deltas(train_t_delta_coeffs, window_size=2)\n",
    "    train_n_derivative_delta_coeffs = compute_deltas(train_n_delta_coeffs, window_size=2)\n",
    "\n",
    "    train_t = np.concatenate((train_t, train_t_delta_coeffs, train_t_derivative_delta_coeffs), axis=1)\n",
    "    train_n = np.concatenate((train_n, train_n_delta_coeffs, train_n_derivative_delta_coeffs), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:13:10.362885Z",
     "end_time": "2023-04-17T21:13:13.737621Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cepstral_mean_subtraction(cepstral_coeffs):\n",
    "    # Calculate the mean of the cepstral coefficients across all frames (axis 0)\n",
    "    mean_coeffs = np.mean(cepstral_coeffs, axis=0)\n",
    "\n",
    "    # Subtract the mean from the original cepstral coefficients\n",
    "    cms_coeffs = cepstral_coeffs - mean_coeffs\n",
    "\n",
    "    return cms_coeffs\n",
    "\n",
    "if cepstral_mean_subtraction_enabled:\n",
    "    train_t = cepstral_mean_subtraction(train_t)\n",
    "    train_n = cepstral_mean_subtraction(train_n)\n",
    "#print(train_t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:13:13.738563Z",
     "end_time": "2023-04-17T21:13:13.741023Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "M_t = 5  # Počet gaussovských komponent\n",
    "MUs_t = train_t[np.random.randint(1, len(train_t), M_t)]  # Počiatočna stredná hodnota\n",
    "COVs_t = [np.cov(train_t.T)] * M_t  # Počiatočna kovariančná matica\n",
    "Ws_t = np.ones(M_t) / M_t\n",
    "\n",
    "M_n = 30\n",
    "MUs_n = train_n[np.random.randint(1, len(train_n), M_n)]\n",
    "COVs_n = [np.cov(train_n.T)] * M_t\n",
    "Ws_n = np.ones(M_n) / M_n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:15:27.144038Z",
     "end_time": "2023-04-17T21:15:27.183134Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for jj in range(30):\n",
    "    # TTL_t je doveryhodnosť\n",
    "    Ws_t, MUs_t, COVs_t, TTL_t = ilib.train_gmm(train_t, Ws_t, MUs_t, COVs_t)\n",
    "    Ws_n, MUs_n, COVs_n, TTL_n = ilib.train_gmm(train_n, Ws_n, MUs_n, COVs_n)\n",
    "    print(f'Iteration: {jj} Total log likelihood: {TTL_t} for target {TTL_n} for non target')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:15:27.543438Z",
     "end_time": "2023-04-17T21:16:03.916481Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P_t=0.5\n",
    "P_n=1.0-P_t\n",
    "\n",
    "score=[]\n",
    "for tst in test_t:\n",
    "    test_modif_t = tst.copy()\n",
    "    test_modif_n = tst.copy()\n",
    "\n",
    "    if coefficients_normalization:\n",
    "        test_modif_t = min_max_normalize(test_modif_t)\n",
    "        test_modif_n = min_max_normalize(test_modif_n)\n",
    "\n",
    "    if delta_coefficients_enabled:\n",
    "        test_t_delta_coeffs = compute_deltas(tst, window_size=2)\n",
    "        test_n_delta_coeffs = compute_deltas(tst, window_size=2)\n",
    "\n",
    "        test_t_derivative_delta_coeffs = compute_deltas(test_t_delta_coeffs, window_size=2)\n",
    "        test_n_derivative_delta_coeffs = compute_deltas(test_n_delta_coeffs, window_size=2)\n",
    "\n",
    "        test_modif_t = np.concatenate((test_modif_t, test_t_delta_coeffs, test_t_derivative_delta_coeffs), axis=1)\n",
    "        test_modif_n = np.concatenate((test_modif_n, test_n_delta_coeffs, test_n_derivative_delta_coeffs), axis=1)\n",
    "\n",
    "    if cepstral_mean_subtraction_enabled:\n",
    "        test_modif_t = cepstral_mean_subtraction(test_modif_t)\n",
    "        test_modif_n = cepstral_mean_subtraction(test_modif_n)\n",
    "\n",
    "    ll_t = ilib.logpdf_gmm(test_modif_t, Ws_t, MUs_t, COVs_t)\n",
    "    ll_n = ilib.logpdf_gmm(test_modif_n, Ws_n, MUs_n, COVs_n)\n",
    "    score.append((sum(ll_t) + np.log(P_t)) - (sum(ll_n) + np.log(P_n)))\n",
    "print(score)\n",
    "print(f\"Fraction of correctly recognized targets: {np.mean(np.array(score) > 0) * 100}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:16:08.118796Z",
     "end_time": "2023-04-17T21:16:08.434533Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score=[]\n",
    "for tst in test_n:\n",
    "    test_modif_t = tst.copy()\n",
    "    test_modif_n = tst.copy()\n",
    "\n",
    "    if coefficients_normalization:\n",
    "        test_modif_t = min_max_normalize(test_modif_t)\n",
    "        test_modif_n = min_max_normalize(test_modif_n)\n",
    "\n",
    "    if delta_coefficients_enabled:\n",
    "        test_t_delta_coeffs = compute_deltas(test_modif_t, window_size=2)\n",
    "        test_n_delta_coeffs = compute_deltas(test_modif_n, window_size=2)\n",
    "\n",
    "        test_t_derivative_delta_coeffs = compute_deltas(test_t_delta_coeffs, window_size=2)\n",
    "        test_n_derivative_delta_coeffs = compute_deltas(test_n_delta_coeffs, window_size=2)\n",
    "\n",
    "        test_modif_t = np.concatenate((tst, test_t_delta_coeffs, test_t_derivative_delta_coeffs), axis=1)\n",
    "        test_modif_n = np.concatenate((tst, test_n_delta_coeffs, test_n_derivative_delta_coeffs), axis=1)\n",
    "\n",
    "    if cepstral_mean_subtraction_enabled:\n",
    "        test_modif_t = cepstral_mean_subtraction(test_modif_t)\n",
    "        test_modif_n = cepstral_mean_subtraction(test_modif_n)\n",
    "\n",
    "    ll_t = ilib.logpdf_gmm(test_modif_t, Ws_t, MUs_t, COVs_t)\n",
    "    ll_n = ilib.logpdf_gmm(test_modif_n, Ws_n, MUs_n, COVs_n)\n",
    "    score.append((sum(ll_t) + np.log(P_t)) - (sum(ll_n) + np.log(P_n)))\n",
    "print(score)\n",
    "print(f\"Fraction of correctly recognized non targets: {np.mean(np.array(score) < 0) * 100}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T21:16:09.367992Z",
     "end_time": "2023-04-17T21:16:11.515646Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T20:17:51.150290Z",
     "end_time": "2023-04-17T20:17:51.175766Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
