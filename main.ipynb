{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T23:25:24.506992Z",
     "end_time": "2023-04-29T23:25:24.697735Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists('SUR_projekt2022-2023.zip'):\n",
    "    !wget https://www.fit.vutbr.cz/study/courses/SUR/public/projekt_2022-2023/SUR_projekt2022-2023.zip\n",
    "    !unzip SUR_projekt2022-2023.zip\n",
    "if not os.path.exists('SUR_projekt2022-2023_eval.zip'):\n",
    "    !wget https://www.fit.vutbr.cz/study/courses/SUR/public/projekt_2022-2023/SUR_projekt2022-2023_eval.zip\n",
    "    !unzip SUR_projekt2022-2023_eval.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delete_dirs = False\n",
    "\n",
    "if delete_dirs:\n",
    "    parent_dirs = [\"train\", \"dev\"]\n",
    "\n",
    "    for parent_dir in parent_dirs:\n",
    "        for i in range(1, 32):\n",
    "            current_dir = os.path.join(parent_dir, str(i))\n",
    "\n",
    "            # Make sure the directory exists\n",
    "            if os.path.exists(current_dir):\n",
    "                for subdir in os.listdir(current_dir):\n",
    "                    subdir_path = os.path.join(current_dir, subdir)\n",
    "                    if os.path.isdir(subdir_path):\n",
    "                        shutil.rmtree(subdir_path)\n",
    "                        print(f\"Removed directory: {subdir_path}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from augment import augment_images\n",
    "import os\n",
    "import shutil\n",
    "import ikrlib as ikrl\n",
    "\n",
    "CLASSES = 31\n",
    "os.mkdir(\"results\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T11:50:11.044025Z",
     "end_time": "2023-04-30T11:50:11.053695Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image\n",
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T22:18:43.234451814Z",
     "start_time": "2023-04-29T22:18:43.103276804Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation_enabled = False\n",
    "\n",
    "# Copy all to train\n",
    "for cls in range(1, CLASSES + 1):\n",
    "    for f in os.listdir(os.path.join(\"dev\", str(cls))):\n",
    "       shutil.copy(os.path.join(\"dev\", str(cls), f), os.path.join(\"train\", str(cls), f))\n",
    "\n",
    "\n",
    "if data_augmentation_enabled:\n",
    "    augment_images('train', 'train/da')\n",
    "    augment_images('dev', 'dev/da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T12:25:19.054093Z",
     "end_time": "2023-04-30T12:25:52.212444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images were successfully loaded\n",
      "Dataset was successfully created\n",
      "Epoch: 0/100, Loss: 119.0357, Accuracy: 0.0806, 5 and 62\n",
      "Epoch: 50/100, Loss: 7.8349, Accuracy: 1.0000, 62 and 62\n",
      "Epoch: 100/100, Loss: 2.8979, Accuracy: 1.0000, 62 and 62\n",
      "Model was successfully trained\n"
     ]
    }
   ],
   "source": [
    "from image import CustomDataset, CNNModel\n",
    "\n",
    "train_x = np.empty((0, 80, 80, 3))\n",
    "train_y = np.empty(0, dtype=int)\n",
    "\n",
    "test_x = np.empty((0, 80, 80, 3))\n",
    "test_y = np.empty(0, dtype=int)\n",
    "\n",
    "for i in range(1, CLASSES + 1):\n",
    "    train_i = np.array(list(ikrl.png_load(os.path.join(\"train\", str(i)), False).values()))\n",
    "    label_i = np.full(len(train_i), i - 1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    train_i = np.array(list(ikrl.png_load(os.path.join(\"dev\", str(i)), False).values()))\n",
    "    label_i = np.full(len(train_i), i - 1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    test_i = np.array(list(ikrl.png_load(os.path.join(\"dev\", str(i)), False).values()))\n",
    "    label_i = np.full(len(test_i), i - 1)\n",
    "    test_x = np.concatenate((test_x, test_i), axis=0)\n",
    "    test_y = np.concatenate((test_y, label_i), axis=0)\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "# convert 80,80,3 to 3,80,80\n",
    "train_x = np.array(train_x)\n",
    "train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "train_tensors = torch.Tensor(train_x)\n",
    "test_tensors = torch.Tensor(test_x)\n",
    "\n",
    "train_dataset = CustomDataset(train_tensors, train_y)\n",
    "test_dataset = CustomDataset(test_tensors, test_y)\n",
    "print(\"Dataset was successfully created\")\n",
    "\n",
    "model = CNNModel(num_classes=31, lr=1e-4)\n",
    "model.train_net(train_dataset, test_dataset, num_epochs=100)\n",
    "print(\"Model was successfully trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T12:28:03.912265Z",
     "end_time": "2023-04-30T12:28:05.250548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 31)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = ikrl.png_load('eval', False)\n",
    "filenames = list(data.keys())\n",
    "filenames = np.array([filename.replace(\"eval/\", \"\") for filename in filenames])\n",
    "eval_data = np.array(list(data.values()))\n",
    "eval_data = np.array(eval_data)\n",
    "eval_data = np.transpose(eval_data, (0, 3, 1, 2))\n",
    "eval_data = torch.Tensor(eval_data)\n",
    "\n",
    "eval_dataset = CustomDataset(eval_data, np.zeros(len(eval_data)))\n",
    "pred = model.predict(eval_dataset)\n",
    "\n",
    "pred = np.stack([tensor.detach().numpy() for tensor in pred])\n",
    "exp_matrix = np.exp(pred)\n",
    "row_sums = exp_matrix.sum(axis=2, keepdims=True)\n",
    "cnn_predictions = exp_matrix / row_sums\n",
    "cnn_predictions = np.squeeze(cnn_predictions, axis=1)\n",
    "print(cnn_predictions.shape)\n",
    "\n",
    "sorted_indices = np.argsort(filenames)\n",
    "sorted_filenames = filenames[sorted_indices]\n",
    "sorted_cnn_prob = np.array(cnn_predictions)[sorted_indices]\n",
    "\n",
    "with open(\"results/cnn_prob_table.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, sorted_cnn_prob):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred)) + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T11:51:04.028630Z",
     "end_time": "2023-04-30T11:51:14.381686Z"
    }
   },
   "outputs": [],
   "source": [
    "from svm import SVCTrain\n",
    "\n",
    "model = SVCTrain()\n",
    "model.train_svc(train_dataset, eval_dataset)\n",
    "svm_prob = model.predict_whole_dataset(eval_data)\n",
    "print(model.predict_whole_dataset(eval_data))\n",
    "\n",
    "# Sort filenames and get the indices for sorting the matrix\n",
    "sorted_indices = np.argsort(filenames)\n",
    "sorted_filenames = filenames[sorted_indices]\n",
    "sorted_svm_prob = np.array(svm_prob)[sorted_indices]\n",
    "\n",
    "# Write the sorted results to a file\n",
    "with open(\"results/svm_prob_table.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, sorted_svm_prob):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred))[1:-1] + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T11:51:16.702713Z",
     "end_time": "2023-04-30T11:53:44.509085Z"
    }
   },
   "outputs": [],
   "source": [
    "from gmm import GMMmodel\n",
    "\n",
    "train_dataset_np = np.array(train_dataset.images)\n",
    "train_dataset_mean_face = np.mean(train_dataset_np, axis=0)\n",
    "plt.imshow(train_dataset_mean_face.transpose(1, 2, 0).astype(np.uint8))\n",
    "plt.title(\"You main not like this but this is what peak performance looks like (mean face) \")\n",
    "plt.axis('off')\n",
    "\n",
    "model = GMMmodel()\n",
    "eval_subs_mean = model.train_gmm(train_dataset, test_dataset, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T11:54:12.012997Z",
     "end_time": "2023-04-30T11:54:20.050304Z"
    }
   },
   "outputs": [],
   "source": [
    "res = model.predict(eval_subs_mean[0])\n",
    "res = res.T\n",
    "\n",
    "# Subtract the maximum value from each row\n",
    "res -= np.max(res, axis=1, keepdims=True)\n",
    "\n",
    "# Calculate the exponentials\n",
    "prob_matrix = np.exp(res)\n",
    "\n",
    "# Normalize the probabilities so that they sum to 1 for each data point\n",
    "gmm_image_prob = prob_matrix / prob_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Normalized probability matrix:\")\n",
    "print(gmm_image_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort filenames and get the indices for sorting the matrix\n",
    "sorted_indices = np.argsort(filenames)\n",
    "sorted_filenames = filenames[sorted_indices]\n",
    "sorted_gmm_image = np.array(gmm_image_prob)[sorted_indices]\n",
    "\n",
    "# Write the sorted results to a file\n",
    "with open(\"results/gmm_image_prob_table.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, sorted_gmm_image):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred))[1:-1] + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T11:54:21.826577Z",
     "end_time": "2023-04-30T11:54:21.842627Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T11:54:25.521768Z",
     "end_time": "2023-04-30T11:54:26.691603Z"
    }
   },
   "outputs": [],
   "source": [
    "from audio import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T11:54:26.692901Z",
     "end_time": "2023-04-30T11:54:26.694690Z"
    }
   },
   "outputs": [],
   "source": [
    "cepstral_mean_subtraction_enabled = False\n",
    "delta_coefficients_enabled = False\n",
    "coefficients_normalization = False\n",
    "\n",
    "audio_adjust_enabled = True\n",
    "reduce_noise_enabled = True\n",
    "data_augmentation_enabled = True\n",
    "data_pre_emphasis = False\n",
    "\n",
    "CLASSES = 31\n",
    "generate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:01:20.141225Z",
     "end_time": "2023-04-30T12:01:20.149012Z"
    }
   },
   "outputs": [],
   "source": [
    "audio = Audio(CLASSES, \"train\", \"eval\")\n",
    "if generate_data:\n",
    "    audio.do_audio_adjust(audio_adjust_enabled)\n",
    "    audio.do_reduce_noise(reduce_noise_enabled)\n",
    "    audio.do_data_augmentation(data_augmentation_enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if data_pre_emphasis:\n",
    "    train_audio, dev_audio = audio.do_data_pre_emphasis()\n",
    "else:\n",
    "    train_audio, dev_audio = audio.do_classic_load()\n",
    "train_audio = audio.do_coefficients_normalization(train_audio, coefficients_normalization)\n",
    "train_audio = audio.do_delta_coefficients(train_audio, delta_coefficients_enabled)\n",
    "train_audio = audio.do_cepstral_mean_subtraction(train_audio, cepstral_mean_subtraction_enabled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:01:20.571595Z",
     "end_time": "2023-04-30T12:01:55.866475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ws, MUs, COVs = audio.train_gmm(train_audio, 3, 40)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:01:59.157480Z",
     "end_time": "2023-04-30T12:02:43.101159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gmm_audio_prob, filenames = audio.eval(dev_audio, Ws, MUs, COVs, eval_format='new')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:03:39.019647Z",
     "end_time": "2023-04-30T12:04:00.831828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filenames = np.array([filename.replace(\"eval/rn/\", \"\") for filename in filenames])\n",
    "# Sort filenames and get the indices for sorting the matrix\n",
    "sorted_indices = np.argsort(filenames)\n",
    "sorted_filenames = filenames[sorted_indices]\n",
    "sorted_gmm_audio_prob = np.array(gmm_audio_prob)[sorted_indices]\n",
    "\n",
    "# Write the sorted results to a file\n",
    "with open(\"results/gmm_audio_prob_table.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, sorted_gmm_audio_prob):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred))[1:-1] + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:04:07.417986Z",
     "end_time": "2023-04-30T12:04:07.434372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Average models result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "average_all = (sorted_gmm_audio_prob + sorted_gmm_image + sorted_svm_prob + sorted_cnn_prob) / 4\n",
    "average_gmm_cnn = (sorted_gmm_audio_prob + sorted_gmm_image + sorted_cnn_prob) / 3\n",
    "average_gmm_audio_cnn = (sorted_gmm_audio_prob + sorted_cnn_prob) / 2\n",
    "\n",
    "with open(\"results/average_all.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, average_all):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred)) + '\\n')\n",
    "\n",
    "with open(\"results/average_gmm_cnn.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, average_gmm_cnn):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred)) + '\\n')\n",
    "\n",
    "with open(\"results/average_gmm_audio_cnn.txt\", \"w\") as f:\n",
    "    for file, correspond_pred in zip(sorted_filenames, average_gmm_audio_cnn):\n",
    "        pred = np.argmax(correspond_pred)\n",
    "        f.write(file + ' ' + str(pred + 1) + ' ' + ' '.join(map(str, correspond_pred)) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:30:17.287475Z",
     "end_time": "2023-04-30T12:30:17.344706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
