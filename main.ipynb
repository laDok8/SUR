{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mikrlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mikrl\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n",
      "File \u001B[0;32m~/SUR2/ikrlib.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m glob\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01manimation\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01manimation\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import ikrlib as ikrl\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from augment import augment_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image\n",
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_enabled = True\n",
    "\n",
    "if data_augmentation_enabled:\n",
    "    augment_images('train', 'train/da')\n",
    "    augment_images('dev', 'dev/da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image import CustomDataset, SmallCNNMultiClass, train\n",
    "\n",
    "CLASSES = 31\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "train_x = np.empty((0,80,80,3))\n",
    "train_y = np.empty((0),dtype=int)\n",
    "\n",
    "test_x = np.empty((0,80,80,3))\n",
    "test_y = np.empty((0),dtype=int)\n",
    "\n",
    "for i in range(1,CLASSES+1):\n",
    "    train_i = np.array(list(ikrl.png_load(os.path.join(\"train\",str(i)), False).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    test_i = np.array(list(ikrl.png_load(os.path.join(\"dev\",str(i)), False).values()))\n",
    "    label_i = np.full(len(test_i),i-1)\n",
    "    test_x = np.concatenate((test_x, test_i), axis=0)\n",
    "    test_y = np.concatenate((test_y, label_i), axis=0)\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "# convert 80,80,3 to 3,80,80\n",
    "train_x = np.array(train_x)\n",
    "train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_tensors = torch.Tensor(train_x)\n",
    "test_tensors = torch.Tensor(test_x)\n",
    "\n",
    "\n",
    "# Create new TensorDataset instances with the modified labels\n",
    "train_dataset = CustomDataset(train_tensors, train_y)\n",
    "test_dataset = CustomDataset(test_tensors, test_y)\n",
    "print(\"Dataset was successfully created\")\n",
    "\n",
    "model = SmallCNNMultiClass()\n",
    "criterion = F.cross_entropy\n",
    "model = model.to(dev)\n",
    "# model = Net().to(dev)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "accuracys, losses = train(model, train_dataset, test_dataset, optimizer, criterion, dev, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "test_x = np.empty((0,80,80,3))\n",
    "test_x = np.array(list(ikrl.png_load('eval', False).values()))\n",
    "test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(test_x))\n",
    "test_loader = DataLoader(test_dataset, batch_size=736)\n",
    "\n",
    "for x in test_loader:\n",
    "    pred = model(x[0].to(dev))\n",
    "    _, pred = torch.max(pred, dim=1)\n",
    "pred = pred + 1\n",
    "print(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm import SVCTrain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from image import CustomDataset\n",
    "CLASSES = 31\n",
    "\n",
    "def png_load(dir_name):\n",
    "    \"\"\"\n",
    "    Loads all *.png images from directory dir_name into a dictionary. Keys are the file names\n",
    "    and values and 2D numpy arrays with corresponding grayscale images\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for f in glob(dir_name + '/*.png'):\n",
    "        features[f] = np.array(Image.open(f), dtype=np.float64)\n",
    "    return features\n",
    "\n",
    "train_x = np.empty((0,80,80,3))\n",
    "train_y = np.empty((0),dtype=int)\n",
    "\n",
    "for i in range(1,CLASSES+1):\n",
    "    train_i = np.array(list(png_load(os.path.join(\"train\",str(i))).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3,random_state=109)\n",
    "\n",
    "train_dataset = CustomDataset(train_x, train_y)\n",
    "\n",
    "model = SVCTrain()\n",
    "model.train(train_dataset, CustomDataset(test_x, test_y))\n",
    "print(model.predict(test_x[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmm import train_gmm, eval, augment_images_gmm\n",
    "\n",
    "CLASSES = 31\n",
    "\n",
    "data_augmentation_enabled = False\n",
    "\n",
    "if data_augmentation_enabled:\n",
    "    for i in range(1,CLASSES+1):\n",
    "        augment_images_gmm(f\"train/{i}\", f\"train/{i}/da\", 10)\n",
    "\n",
    "dev_subs_mean, ws_list, mus_list, covs_list = train_gmm()\n",
    "eval(dev_subs_mean, ws_list, mus_list, covs_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Audio\n\u001B[1;32m      3\u001B[0m cepstral_mean_subtraction_enabled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m      4\u001B[0m delta_coefficients_enabled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/SUR2/audio.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logsumexp\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mikrlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01milib\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "File \u001B[0;32m~/SUR2/ikrlib.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m glob\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01manimation\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01manimation\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "from audio import Audio\n",
    "\n",
    "cepstral_mean_subtraction_enabled = False\n",
    "delta_coefficients_enabled = False\n",
    "coefficients_normalization = False\n",
    "\n",
    "audio_adjust_enabled = True\n",
    "reduce_noise_enabled = True\n",
    "data_augmentation_enabled = True\n",
    "data_pre_emphasis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLASSES = 31\n",
    "audio = Audio(CLASSES, \"train\", \"eval\")\n",
    "audio.do_audio_adjust(audio_adjust_enabled)\n",
    "audio.do_reduce_noise(reduce_noise_enabled)\n",
    "audio.do_data_augmentation(data_augmentation_enabled)\n",
    "if data_pre_emphasis:\n",
    "    train_audio, dev_audio = audio.do_data_pre_emphasis()\n",
    "else:\n",
    "    train_audio, dev_audio = audio.do_classic_load()\n",
    "train_audio = audio.do_coefficients_normalization(train_audio, coefficients_normalization)\n",
    "train_audio = audio.do_delta_coefficients(train_audio, delta_coefficients_enabled)\n",
    "train_audio = audio.do_cepstral_mean_subtraction(train_audio, cepstral_mean_subtraction_enabled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m audio \u001B[38;5;241m=\u001B[39m \u001B[43mAudio\u001B[49m(CLASSES, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_pre_emphasis:\n\u001B[1;32m      3\u001B[0m     train_audio, dev_audio \u001B[38;5;241m=\u001B[39m audio\u001B[38;5;241m.\u001B[39mdo_data_pre_emphasis()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Audio' is not defined"
     ]
    }
   ],
   "source": [
    "audio = Audio(CLASSES, \"train\", \"eval\")\n",
    "if data_pre_emphasis:\n",
    "    train_audio, dev_audio = audio.do_data_pre_emphasis()\n",
    "else:\n",
    "    train_audio, dev_audio = audio.do_classic_load()\n",
    "train_audio = audio.do_coefficients_normalization(train_audio, coefficients_normalization)\n",
    "train_audio = audio.do_delta_coefficients(train_audio, delta_coefficients_enabled)\n",
    "train_audio = audio.do_cepstral_mean_subtraction(train_audio, cepstral_mean_subtraction_enabled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ws, MUs, COVs = audio.train_gmm(train_audio, 3, 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_classes, accuracy = audio.eval(dev_audio, Ws, MUs, COVs, eval_format='new')\n",
    "print(predicted_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Majority voting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def majority_voting(pred_gmm, pred_svm, pred_cnn):\n",
    "    return np.array([np.argmax(np.bincount([a, b, c])) for a, b, c in zip(pred_gmm, pred_svm, pred_cnn)])\n",
    "\n",
    "# Assuming you have already classified the test images using the three models\n",
    "# and have the predictions in the following variables:\n",
    "# pred_gmm, pred_svm, pred_cnn\n",
    "\n",
    "# Combine the predictions using majority voting\n",
    "pred_ensemble = majority_voting(pred_gmm, pred_svm, pred_cnn)\n",
    "\n",
    "# Calculate the accuracy of the ensemble\n",
    "ensemble_accuracy = np.sum(test_y == pred_ensemble) / len(test_y)\n",
    "print(\"Ensemble accuracy:\", ensemble_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
