{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:30:32.209088Z",
     "start_time": "2023-04-24T21:30:32.167504Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:30:32.209399Z",
     "start_time": "2023-04-24T21:30:32.209057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_augmentation_enabled = True\n",
    "CLASSES = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:30:32.209608Z",
     "start_time": "2023-04-24T21:30:32.209263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def augment_images(input_dir, output_dir, num_augmentations=int(1e3)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for cls in range(1, CLASSES+1):\n",
    "        in_dir = input_dir + '/' + str(cls)\n",
    "        print('Augmenting images in ' + in_dir)\n",
    "        out_dir = output_dir + '/' + str(cls)\n",
    "        print('Augmenting into ' + out_dir)\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        p = Augmentor.Pipeline(source_directory=in_dir, output_directory=\"out\")\n",
    "        p.random_brightness(probability=0.4, min_factor=0.01, max_factor=0.5)\n",
    "        p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "        p.zoom_random(probability=0.5, percentage_area=0.8)\n",
    "        p.flip_left_right(probability=0.3)\n",
    "        p.skew_tilt(probability=0.5, magnitude=0.1)\n",
    "        p.sample(num_augmentations)\n",
    "        #out is relative for augmentator :/ move\n",
    "        os.rename(os.path.join(input_dir,str(cls),'out'), os.path.join(output_dir,str(cls)))\n",
    "\n",
    "# note that function will fail if augmentations were already present\n",
    "if data_augmentation_enabled:\n",
    "    augment_images('train', 'train/da')\n",
    "    augment_images('dev', 'dev/da', num_augmentations=int(1e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:30:32.209737Z",
     "start_time": "2023-04-24T21:30:32.209478Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels) -> None:\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.images[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def png_load(dir_name):\n",
    "    \"\"\"\n",
    "    Loads all *.png images\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for f in glob(dir_name + '/*.png'):\n",
    "        features[f] = np.array(Image.open(f), dtype=np.float64)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.empty((0,80,80,3))\n",
    "train_y = np.empty((0),dtype=int)\n",
    "\n",
    "test_x = np.empty((0,80,80,3))\n",
    "test_y = np.empty((0),dtype=int)\n",
    "\n",
    "for i in range(1,CLASSES+1):\n",
    "    train_i = np.array(list(png_load(os.path.join(\"train\",str(i))).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    train_i = np.array(list(png_load(os.path.join(\"dev\",str(i))).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    # train_i = np.array(list(png_load(os.path.join(\"train/da\",str(i))).values()))\n",
    "    # label_i = np.full(len(train_i),i-1)\n",
    "    # train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    # train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    # train_i = np.array(list(png_load(os.path.join(\"dev/da\",str(i))).values()))\n",
    "    # label_i = np.full(len(test_i),i-1)\n",
    "    # train_x = np.concatenate((train_x, test_i), axis=0)\n",
    "    # train_y = np.concatenate((train_y, label_i), axis=0)\n",
    "\n",
    "    test_i = np.array(list(png_load(os.path.join(\"dev\",str(i))).values()))\n",
    "    label_i = np.full(len(test_i),i-1)\n",
    "    test_x = np.concatenate((test_x, test_i), axis=0)\n",
    "    test_y = np.concatenate((test_y, label_i), axis=0)\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "# convert 80,80,3 to 3,80,80\n",
    "train_x = np.array(train_x)\n",
    "train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_tensors = torch.Tensor(train_x)\n",
    "test_tensors = torch.Tensor(test_x)\n",
    "\n",
    "\n",
    "# Create new TensorDataset instances with the modified labels\n",
    "train_dataset = CustomDataset(train_tensors, train_y)\n",
    "test_dataset = CustomDataset(test_tensors, test_y)\n",
    "print(\"Dataset was successfully created\")\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:30:58.289873Z",
     "start_time": "2023-04-24T21:30:32.209686Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SmallCNNMultiClass(nn.Module):\n",
    "    def __init__(self, num_classes=CLASSES):\n",
    "        super(SmallCNNMultiClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(8)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(16)\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "        self.fc1 = nn.Linear(32 * 10 * 10, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #VGG like\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 40x40x8\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 20x20x16\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 10x10x32\n",
    "        x = x.view(-1, 32 * 10 * 10)  # 3200\n",
    "        x = self.fc1(x)  # 128\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:24:08.218935Z",
     "start_time": "2023-04-24T21:23:19.704793Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "model = SmallCNNMultiClass()\n",
    "criterion = F.cross_entropy\n",
    "model = model.to(dev)\n",
    "# model = Net().to(dev)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "losses = []\n",
    "accuracys = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(dev), labels.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if not epoch % 10:\n",
    "    # Evaluation on the dev set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dev_loader:\n",
    "                inputs, labels = inputs.to(dev), labels.to(dev)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        losses.append(train_loss)\n",
    "        accuracys.append(accuracy)\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}, {correct} and {total}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracys)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model-{accuracy:.4f}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
