{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import Augmentor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:41:25.780008Z",
     "end_time": "2023-04-23T22:41:25.820475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation_enabled = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:42:15.190925Z",
     "end_time": "2023-04-23T22:42:15.231357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def augment_images(input_dir, output_dir, num_augmentations=int(1e2)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for cls in range(1, 3):\n",
    "        in_dir = input_dir + '/' + str(cls)\n",
    "        print('Augmenting images in ' + in_dir)\n",
    "        out_dir = output_dir + '/' + str(cls)\n",
    "        print('Augmenting into ' + out_dir)\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        p = Augmentor.Pipeline(source_directory=in_dir, output_directory=\"out\")\n",
    "        p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "        p.zoom_random(probability=0.5, percentage_area=0.8)\n",
    "        p.flip_left_right(probability=0.3)\n",
    "        p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=1)\n",
    "        p.skew_tilt(probability=0.5, magnitude=0.1)\n",
    "        p.random_erasing(probability=0.2, rectangle_area=0.1)\n",
    "        p.sample(num_augmentations)\n",
    "        #out is relative for augmentator :/ move\n",
    "        os.rename(os.path.join(input_dir,str(cls),'out'), os.path.join(output_dir,str(cls)))\n",
    "\n",
    "# note that function will fail if augmentations were already present\n",
    "if data_augmentation_enabled:\n",
    "    augment_images('dev', 'dev/da')\n",
    "    augment_images('train', 'train/da')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:52:27.023415Z",
     "end_time": "2023-04-23T23:52:36.874151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels) -> None:\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.images[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "CLASSES = 2\n",
    "\n",
    "def png2fea2(dir_name):\n",
    "    \"\"\"\n",
    "    Loads all *.png images from directory dir_name into a dictionary. Keys are the file names\n",
    "    and values and 2D numpy arrays with corresponding grayscale images\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for f in glob(dir_name + '/*.png'):\n",
    "        features[f] = np.array(Image.open(f).convert('L'), dtype=np.float64)\n",
    "    return features\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:50:46.310530Z",
     "end_time": "2023-04-23T23:50:46.351256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_x = np.empty((0,80,80))\n",
    "train_y = np.empty((0),dtype=int)\n",
    "\n",
    "test_x = np.empty((0,80,80))\n",
    "test_y = np.empty((0),dtype=int)\n",
    "\n",
    "for i in range(1,CLASSES+1):\n",
    "    train_i = np.array(list(png2fea2(os.path.join(\"train/da\",str(i))).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y,label_i), axis=0)\n",
    "\n",
    "    test_i = np.array(list(png2fea2(os.path.join(\"dev/da\",str(i))).values()))\n",
    "    label_i = np.full(len(test_i),i-1)\n",
    "    test_x = np.concatenate((test_x, test_i), axis=0)\n",
    "    test_y = np.concatenate((test_y,label_i), axis=0)\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "class SmallCNNMultiClass(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SmallCNNMultiClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(32 * 20 * 20, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 20 * 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "     #TODO pocet trid a softmax odstran\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_tensors = torch.Tensor(train_x).unsqueeze(1)\n",
    "test_tensors = torch.Tensor(test_x).unsqueeze(1)\n",
    "\n",
    "# Create new TensorDataset instances with the modified labels\n",
    "train_dataset = CustomDataset(train_tensors, train_y)\n",
    "test_dataset = CustomDataset(test_tensors, test_y)\n",
    "print(\"Dataset was successfully created\")\n",
    "# import random\n",
    "# x, y = random.choice(train_dataset)\n",
    "# print(y)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(x[0,:,:])\n",
    "# plt.savefig('idk.png')\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SmallCNNMultiClass()\n",
    "criterion = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "\n",
    "    # Evaluation on the dev set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += torch.sum(predicted.values == labels).item() / len(predicted)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:52:49.380448Z",
     "end_time": "2023-04-23T23:53:51.312053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
