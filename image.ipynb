{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import Augmentor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:30:32.167504Z",
     "end_time": "2023-04-24T21:30:32.209088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation_enabled = True\n",
    "CLASSES = 31"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:30:32.209057Z",
     "end_time": "2023-04-24T21:30:32.209399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def augment_images(input_dir, output_dir, num_augmentations=int(1e3)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for cls in range(1, CLASSES+1):\n",
    "        in_dir = input_dir + '/' + str(cls)\n",
    "        print('Augmenting images in ' + in_dir)\n",
    "        out_dir = output_dir + '/' + str(cls)\n",
    "        print('Augmenting into ' + out_dir)\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        p = Augmentor.Pipeline(source_directory=in_dir, output_directory=\"out\")\n",
    "        p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "        p.zoom_random(probability=0.5, percentage_area=0.8)\n",
    "        p.flip_left_right(probability=0.3)\n",
    "        p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=1)\n",
    "        p.skew_tilt(probability=0.5, magnitude=0.1)\n",
    "        p.random_erasing(probability=0.2, rectangle_area=0.1)\n",
    "        p.sample(num_augmentations)\n",
    "        #out is relative for augmentator :/ move\n",
    "        os.rename(os.path.join(input_dir,str(cls),'out'), os.path.join(output_dir,str(cls)))\n",
    "\n",
    "# note that function will fail if augmentations were already present\n",
    "if data_augmentation_enabled:\n",
    "    augment_images('train', 'train/da')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:30:32.209263Z",
     "end_time": "2023-04-24T21:30:32.209608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels) -> None:\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.images[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def png_load(dir_name):\n",
    "    \"\"\"\n",
    "    Loads all *.png images\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for f in glob(dir_name + '/*.png'):\n",
    "        features[f] = np.array(Image.open(f), dtype=np.float64)\n",
    "    return features\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:30:32.209478Z",
     "end_time": "2023-04-24T21:30:32.209737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_x = np.empty((0,80,80,3))\n",
    "train_y = np.empty((0),dtype=int)\n",
    "\n",
    "test_x = np.empty((0,80,80,3))\n",
    "test_y = np.empty((0),dtype=int)\n",
    "\n",
    "for i in range(1,CLASSES+1):\n",
    "    train_i = np.array(list(png_load(os.path.join(\"train/da\",str(i))).values()))\n",
    "    label_i = np.full(len(train_i),i-1)\n",
    "    train_x = np.concatenate((train_x, train_i), axis=0)\n",
    "    train_y = np.concatenate((train_y,label_i), axis=0)\n",
    "\n",
    "    test_i = np.array(list(png_load(os.path.join(\"dev\",str(i))).values()))\n",
    "    label_i = np.full(len(test_i),i-1)\n",
    "    test_x = np.concatenate((test_x, test_i), axis=0)\n",
    "    test_y = np.concatenate((test_y,label_i), axis=0)\n",
    "\n",
    "print(\"Images were successfully loaded\")\n",
    "\n",
    "# convert 80,80,3 to 3,80,80\n",
    "train_x = np.array(train_x)\n",
    "train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "class SmallCNNMultiClass(nn.Module):\n",
    "    def __init__(self, num_classes=CLASSES):\n",
    "        super(SmallCNNMultiClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 10 * 10, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #VGG like\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 40x40x8\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 20x20x16\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 10x10x32\n",
    "        x = x.view(-1, 32 * 10 * 10)  # 3200\n",
    "        x = F.relu(self.fc1(x))  # 128\n",
    "        x = self.fc2(x)  # 2\n",
    "        return x\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_tensors = torch.Tensor(train_x)\n",
    "test_tensors = torch.Tensor(test_x)\n",
    "\n",
    "\n",
    "# Create new TensorDataset instances with the modified labels\n",
    "train_dataset = CustomDataset(train_tensors, train_y)\n",
    "test_dataset = CustomDataset(test_tensors, test_y)\n",
    "print(\"Dataset was successfully created\")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SmallCNNMultiClass()\n",
    "criterion = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:30:32.209686Z",
     "end_time": "2023-04-24T21:30:58.289873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if not epoch % 10:\n",
    "        # Evaluation on the dev set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dev_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch: {epoch}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}, {correct} and {total}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T21:23:19.704793Z",
     "end_time": "2023-04-24T21:24:08.218935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
